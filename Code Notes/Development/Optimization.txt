/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// PROGRAMMING OPTIMIZATION
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

• A compiler may reorder instructions for the sake of parallel execution
• Branches are often predicted before evaluated, hard to predict branches can be costly
• Compiler will always select the most efficient integer size if you declare an int
• Unsigned is faster than signed when you divide or % with a constant
• char, short, bool slightly less efficient as can be converted to int when doing calculations
• << quicker than multiplying and >> quicker than dividing for power of two values
• Signed/Unsigned int conversion costless, Int/Floating Point conversion expensive
• Constant expressions eg. 2.0/3.0 replaced by their results at compile time
• In most cases, double calculations take no more time than floats but don't mix the two
• Floating point division by a constant should be done by multiplying with the reciprocal
• Switch statements with incrementing labels effecient as implemented as jump target table
• Faster to use memset, memcpy and cstring methods though unsafe
• std::string if > 15 characters (short string optimization) can cause a heap allocation
• Common maths functions (sin, pow, sqrt) with constants not always replaced at compile time
• std::function larger/slower than internal type of lambda
• STL container empty() is always O(1), size() may be O(n) depending on container
• Loop conditions are evaluated each iteration, evaluate any constants before loop starts

===============================================================================================================
CACHE-FRIENDLY PROGRAMMING
===============================================================================================================

• Cache misses are where data needs to be fetched from RAM
• Memory stored together is fetched together: whole cache line is taken even if only a byte is required
• Virtual functions can induce cache misses during look up if function is not called often
• Data can complete for same cache lines (large pow of 2 arrays) resulting in excessive writing/flushing 
• Fragmentation of heap means more cache misses

-------------------------------------------------------------------------------------------------------------
ARRAYS
-------------------------------------------------------------------------------------------------------------
• Linear arrays are cache-friendly
• Hardware can pre-fetch elements if traversal is forwards/backwards in predictable way
• 2D arrays should always have outer loop rows, inner loop columns where arr[row][column]
    - Other row members are part of cache line when fetched and fast to traverse
    - Column members cause a cache miss

-------------------------------------------------------------------------------------------------------------
OBJECTS
-------------------------------------------------------------------------------------------------------------
• Object is aligned in memory so if single member is used often chunk of object will be cached
• Reorder class members so the data aligns without extra padding to reduce amount of data fetched
• Store any frequently accessed booleans in seperate array

-------------------------------------------------------------------------------------------------------------
FALSE SHARING
-------------------------------------------------------------------------------------------------------------
• Seperate cores have same data cached and one writes to it with synchronisation:
    - Entire cache line is invalidated
    - Entire cache line is fetched again
    - This includes memory that may not be related to the data written to
    - Can affect globals/statics/arrays as they are often allocated together

int result[n];
for (int i = 0; i < n; ++i) 
{
    RunThread([i]()
    {
        // Every write to result will invalidate other threads if on seperate cores
        // Minimise amount of times result[] is written to by using a temp var
        for(auto obj : objs) { /*if calculations then*/ result[i] += x; }
    });
}

===============================================================================================================
MEMORY ALLOCATORS
===============================================================================================================

• May improve performance/memory usage and reduce fragmentation of heap
• Handle requests for allocation and deallocation of memory for a container
• Useful if lots of small allocations for associative containers as default is slow

MEMORY POOL ALLOCATOR
• Custom allocator design where large block of memory is allocated beforehand
• Requests by container are from the pool and returned to the pool
• Pool is deallocated when lifetime of container ends

===============================================================================================================
SYMMETRIC INSTRUCTION IN MULTIPLE DATA (SIMD)
===============================================================================================================

• Same intructions done in parallel on multiple data objects
• Registers (XMM, MMX, YMM) optimized for doing same work on vectorized floats and/or ints
• Auto-used by compilier if 4 floats/ints aligned together in memory
• Best used on rendering algorithms and math libaries
• Best used when data members don't rely on outcome of previous member calculations

LINEAR SUM OF ARRAY
float arr[100]
for(int i = 0; i < 100; ++i)
    sum += arr[i]

SIMD SUM OF ARRAY
float arr[100]
for(int i = 0; i < 100; i+=4)
    s0 += arr[i]
    s1 += arr[i+1]
    s2 += arr[i+2]
    s3 += arr[i+3]
sum = s0 + s1 + s2 + s3

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// RENDERING OPTIMIZATION
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

• Don't allocate stencil if you don't use it
• R5G6B5 color sufficient for dynamic reflection maps
• Use low resolution (<256x256) 8-bit normalization cube-maps
• Render a depth-only pass before color pass to reduce overdraw
• Use power of 2 allocations to reduce fragmentation (trade off can be wasted allocation space)
• Alpha tested only objects don't need to be sorted by depth

FARPLANE CULLING
• Any objects past the farplane are culled
• Limitation is if plane is too close objects seen disappearing
• This can be fixed by using fog to hide far distances

FRUSTUM CULLING
• Only objects in frustum are drawn. 
• If Polygon outside it's not visible and hence discarded
• If partially inside its clipped so outside parts are removed

FRONT/BACKFACE CULLING
• Winding order of vertices indicates which way polygon is facing

CLIPPING
• Any screen space coordinates outside [–1,–1,0] to [1,1,1] culled

OCCLUSION CULLING
• Identifies parts of the scene visible/not visible to the viewer
• Objects behind other objects are discarded
• Can use a plane to represent occluder (similar to frustum culling)
• Can use Potential Visible Sets for indoor scenes

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// SHADER OPTIMIZATION
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

• Floats faster for calculations, integers faster for indexing
• Use half instead of float where strict precision isn't important
• Compiler may optimize isnan() and isfinite() calls
• NaN * 0 = 0 not NaN except with precise keyword
• Use of static keyword for global bools only evaluates the one path instead of both
• If missing components in vertex stream, auto sets z/y to 0.0 and w to 1.0
• Normalize normals in pixel shader as may not be still normalized after vertex shader interpolation
• Texture read is fastest when accessing adjacent pixels due to cache
• Code that doesn't rely on texture read can be auto moved by compilier in front of a read to parallelize

CACHE COMMONLY USED CONSTANTS
const float4 constants = float4(1.0, 0.0, 0.5, 0.2);

VECTORISE OPERATIONS
float a,b,c,d;
a = x + 1;    
b = x + 2; => float4 vec;
c = x + 3;    vec = x + float4(1,2,3,4)
d = x + 4;

SUMMING VECTOR COMPONENTS
float sum = a + b + c + d;                           Inefficient
float sum = myFlt.x + myFlt.y + myFlt.z + myFlt.w;   Inefficient
float sum = dot(myFlt4, vec4(1.0));                  Faster to use dot to sum
float sum = dot(myFlt3, vec4(1.0).xyz);
float sum = dot(vec4(a,b,c,d), vec4(1.0));

SETTING VECTOR LENGTH
• Uses less instructions
50.0 * normalize(vec)  =>  vec * (50.0 * rsqrt(dot(vec, vec)))

MAD (MULTIPLY THEN ADD)
• Usually single-cyle and fast
x * (1.0 - x)          =>  x - (x * x)              Expand out brackets
x * (y + 1.0)          =>  (x * y) + x              Expand out brackets
(x + c) * (x - c)      =>  x * x + (-c * c)         Expand out brackets
(x + a) / b            =>  x * (1.0 / b) + (a / b)  Expand out brackets
(x / 2.0) + 1.0        =>  (x * 0.5) + 1.0          Divide may not be optimized, convert to multiply
x += a * b + c * d     =>  x += a * b; x += c * b   Move to seperate lines

BUILT-IN-FUNCTIONS
a / (x * b)       =>  rcp(x) * a / b      a / b implemented as a * rcp(b) but not always.
(x + a) / x       =>  a * rcp(x) + 1      Check if explicitly using rcp gives better results
1.0 / sqrt(x)     =>  rsqrt(x)            1.0/sqrt(x) maps to rcp(sqrt(x)): instead use single instruction
abs(x * y)        =>  abs(x) * abs(y)     Use abs() on input or it forces an extra MOV 
-(x * y)          =>  -x * y              Use - on input or it forces an extra MOV 
1.0 - saturate(x) =>  saturate(1.0 - x)   Use saturate() on output or it forces an extra MOV
min(x) or max(x)  =>  saturate(x)         Saturate() cheaper than min or max
step() or sign()  =>  if {} else {}       Conditional assigment faster

SWIZZLE MASKS
• Faster than adding both seperately
gl_Position.x = in_pos.x; 
gl_Position.y = in_pos.y;
gl_Position.xy = in_pos.xy;

PACKING ARRAYS/VALUES AS FLOAT4
• Arrays are always packed as float4 even if only using a float
• Packing as float4 saves space but can have instruction cost accessing members
float4 myArray[25];                          Rather than float myARray[100]
float value = myArray[index/4][index%4];     To access values
float myArr[100] = (float[100])myArray;      Does not cast: copies and ineffeciant!
