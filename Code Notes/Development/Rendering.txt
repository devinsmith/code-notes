/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// RENDER ENGINES
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

===================================================================================
|               |           DirectX               |           OpenGL              |
===================================================================================
| Screen Origin |           Top Left              |         Lower Left            |
| Winding Order |           Clockwise             |        Anticlockwise          |
| Z Axis        |            +Z Axis              |          -Z Axis              |
| ---------------------------------------------------------------------------------
| Transform     |      Scale * Rot * Trans        |      Trans * Rot * Scale      |
| Order         |  Vertex * World * View * Proj   |  Proj * Veiw * World * Vertex |
|----------------------------------------------------------------------------------
| Coordinate    |      Row Major Left Handed      |  Column Major Right Handed    |
| System        |  Right.x  Right.y   Right.z  0  |  Right.x  Up.x  For.x  Pos.x  |
|               |  Up.x     Up.y      Up.z     0  |  Right.y  Up.y  For.y  Pos.y  |
|               |  For.x    For.y     For.z    0  |  Right.z  Up.z  For.z  Pos.z  |
|               |  Pos.x    Pos.y     Pos.z    1  |    0       0       0     1    |
===================================================================================

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// RENDER PIPELINE
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

TEXEL: One unit of a texture
PIXEL: One unit of the screen
FRAGMENT: Potential pixel. Each fragment has a pixel location, a depth value, color/texture values
HOMOGENEOUS CLIP SPACE: Screen space multiplied by 'w' component

01) FRUSTUM CULLING: Culls and creates list of meshes based on view frustum
02) VERTEX SHADER: Gets input vertex data, converts to homogenous clip space
03) GEOMETRY SHADER: Hull shader, Tessellator shader, Geometry shader
04) BACKFACE CULLING: Face culling occurs depending on vert winding order
05) CLIPPING: Clips any vertices outside the visible screen (If x,y is in range [-w,w] and z is in range [0,w] then okay)
06) SCREEN MAPPING: Homogenous clip space transformed into screen space
07) RASTERIZATION: 2D shape fitted into pixels

    TRIANGLE TRAVERSAL:
     • If the center of pixel is enclosed in shape, pixel is fully filled. 
     • This creates a stepping, aliased effect. 
     • 2D object may visibly shift in position during this process

    FRAGMENT GENERATION:
    • Every pixel covered by shape is a Fragment. 
    • Fragment values are interpolated from the 2D triangles they're made up of

08) PIXEL SHADING: Gets interpolated vertex data as fragments, outputs pixel colors
09) COMPOSITION: Depth testing, Stencil testing, Alpha testing, Alpha blending
10) FINAL SCENE: Back buffer is switched with front buffer and presented

===============================================================================================================
FORWARD SHADING
===============================================================================================================
• Renders lighting with diffuse pass
• Easy to render transparency
• Expensive to do post effects
• Are limited in amount of lights

1) Render the scene with any lights that affect it to a color buffer
2) Render the scene again for additional information or output to additional buffers in color pass
3) Perform any post effects and present final image to the back buffer

===============================================================================================================
DEFERRED SHADING
===============================================================================================================
• Defers lighting to its own pass
• Difficult to render transparecy
• Cheap to do post effects
• Can have many multiple lights

1) Render the scene once sending attributes to a G-buffer
   Attributes include: Normals, Depth, Diffuse, Specular, Ambient etc.
2) Render all lights as geometry with attenuation/intensity
   Point light: Sphere, Spot light: Cone, Directional light: Full screen quad
3) Combine the lighting texture with the G-buffer calculating the color 
   contribution of the light to the final pixel
4) Perform any post effects with the ability to use the G-buffer

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// GRAPHICS BUFFERS
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

DOUBLE/TRIPLE BUFFERING
• Double Buffering: Back Buffer is rendered to and copied to the Frame Buffer 
• Tearing can occur if monitor refreshes during this copy
• VSync prevents tearing by preventing the copy until after a refresh
• For higher fps than refresh rate, caps copying to refresh rate
• For lower fps than refresh rate, lowers the fps to a multiple of the refresh rate
• Triple Buffering: Uses an additional buffer and fixes additional lowering of fps due to VSync

DEPTH/Z BUFFER
• Saves projected depths of models from viewer (0.0->1.0)
• Needs to be same size or larger than connected color buffer
• Writing to can be turned on/off (ZWRITEENABLE) and affected by comparion function

DEPTH BUFFER COMPARISON FUNCTION
• Discards the incoming fragment if a depth comparison fails
• ZFunc = Never         Don't add to depth buffer
• ZFunc = LessEqual     Only add if depth value <= current value in buffer
• ZFunc = Less          Only add if depth value < current value in buffer
• ZFunc = GreaterEqual  Only add if depth value >= current value in buffer
• ZFunc = Greater       Only add if depth value > current value in buffer
• ZFunc = Always        Always add to depth buffer

DEPTH BUFFER ACCURACY
• Inaccuracy causes z-fighting where triangles have same value in buffer
• Accuracy dependent on:
    - Buffer storage size (32 or 16 bits)
    - Distance between near/far planes
    - Distance between near/origin
• Near getting closer to origin gives less accuracy to values close to far plane
• Near-far distance increasing gives less accuracy to values close to far plane
• Objects together close to far plane z values may be rounded as same value since more 
  of buffer is used for objects closer to near due to non-linear scaling into the buffer
    
STENCIL BUFFER
• masks areas during rendering; specifies what's hidden/shown
• Holds on/off flag

ATTRIBUTE BUFFER
• Buffer of integers
• Used to specify which triangles belong to each subset of a mesh with 
  multiple parts (01120 means triangle 1 belongs to subset 0, triangle 
  2 belongs to subset 1 etc.)

RENDER TARGETS
• Comprised of a color buffer and a depth/stencil buffer 

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// TRANSFORMATIONS
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

----------------
|  YAW:    Y   |
|  PITCH:  X   |
|  ROLL:   Z   |
----------------

EULER ANGLES
• Set of pitch, roll, yaw combined to form a matrix
• Suffer from gimbal lock
• Less storage space needed (3 values)

MATRICES: 
• Suffer from gimbal lock if used with Euler Angles
• More storage space needed (12 values)
• Slow, rounding errors

QUATERNIONS: 
• No Gimbal lock
• Less storage space needed (4 values)
• Fast, less rounding errors

GIMBAL LOCK
• A set of three gimbals mounted together to allow three degrees of freedom
• If the middle gimbal is rotated greater than 90, the top and bottom gimbals 
  are aligned and in gimbal lock losing a degree of freedom. 

VIEW MATRIX
• Inverse of the Camera World Matrix
• changes the world scene basis so the camera is at the origin

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// PROJECTION
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

VIEW FRUSTUM:
• Pyramid volume from camera to world, has near and front clipping planes

ORTHOGONAL PROJECTION MATRIX:
• Objects remain same size regardless of depth

PERSPECTIVE PROJECTION MATRIX:
• Objects different sizes according to depth, uses horizon as vanishing point 
• Constructed from:
    - Field of view (α)
    - Aspect ratio width/height (R)
    - Z-value of near plane (n)
    - Z-value of far plane (f)

USING PERSPECTIVE PROJECTION MATRIX:
• For vertex view space coordinates x,y positions need to be between [-1,1]
• For vertex view space coordinate z, depth needs to be between [0,-1]

tan(b/2) = R*tan(α/2)
tan(b/2)*n = W/2
tan(α/2)*n = H/2

 A = 1/(R*tan(α/2))
 B = 1/(R*tan(b/2))
 C = f/(f-n)
 D = -fn/(f-n)

         | A 0 0 0 |
[x y z 1]| 0 B 0 0 | = [Ax By (Cz+D)  z]
         | 0 0 C 1 |   HOMOGENEOUS CLIP SPACE
         | 0 0 D 0 |
         PROJ MATRIX

In homogeneous clip space: culling/clipping
If x,y is in range [-w,w] and z is in range [0,w] then okay
To get final coordinate, divide by w (which is screen space z)

[x' y' z' 1] = [Ax/z  By/z  C+(D/z)  1]
 --------------------------------------
| x' = x/(zRtan(α/2))        = Ax/z    |
| y' = y/(ztan(α/2))         = By/z    |
| z' = (f/f-n)-(fn/(z(f-n))) = C+(D/z) |
 --------------------------------------

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// COLOUR
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

8bit   RGB:  Only 256 colors to use
24bit  RGB:  Each channel has 8bits (256 colors)
32bit  ARGB: Each channel has 8bits (256 colors) including 8bit alpha channel

HSB (Hue/Saturation/Brightness)        Cylindrical colour representation
CMYK (Cyan/Magenta/Yellow/Key[Black])  Subtractive colour model
RGB (Red/Green/Blue)                   Additive colour model

HUE = Particular colour in rainbow
SATURATION = How rich a colour is
VALUE = How much Black/White a colour has
TINTS = Saturation decreases
SHADES = Value decreases
TONES = Saturation/Value decreases

COLOUR BLENDING
• Linear blending loses saturation between colours
• Blending must occur in polar coordinate space to maintain saturation
• Polar coordinate space: HSV/HSB, CIE-Lab
• Note add primary colour = 6 check to primary colour = 0 when blending hues

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// TEXTURES
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

TGA = Targa
PNG = Portable Network Graphics
JPEG = Joint Photography Experts Group
BMP = Bitmap
GIF = Graphics Interchange Format

SANS-SERIF FONT: rounded edges of characters
SERIF FONT: little lines on edges of characters

TEXTURE MAPPING: UV coordinates for 2D image
CUBE MAPPING: UVW coordinates for 3D cube image
MINFILTER: Texture filter used when shrinking textures
MAGFILTER: Texture filter used when magnifying textures

POINT FILTERING: 
• Nearest Neighbour/Box Filtering
• Nearest texel is chosen to the given UV coordinates
• If coordinates are on texel border, UVs are rounded

LINEAR FILTERING:
• Bilinear/Trilinear filtering
• Looks at 2x2 texels surrounding the UVs and calculates color using weights
• If UVs totally in one texel: 100% that texel
• If UVs on border between two texels: 50% each
• If UVS on border between four texels: 25% each
• Trilinear: Fixes artifact occurs when stitching various mipmap levels together

ANISOTROPIC FILTERING: 
• Most consuming of all filters
• Avoids blur at sharp angles/distances
• Prevents distortion when angle between camera forward vector and poly normal is large

MIPMAP:
• Mip = multum in parvo; 'many things in a small place'
• Series of power of 2 texture created from original texture

MIPFILTER:
• None disables mipmapping
• Point chooses mipmap level that is closest in size to geometry and filter
• Linear chooses Two mipmap levels that are closest in size to geometry then
  filter both and lineraly combine them

PROJECTIVE TEXTURING:
• Method of projecting a texture into a 3D scene
• Transform local position of vert by light's worldViewProj matrix
• Pass position to pixel shader
• Position will be in homogenous clip space so divide by w
• Scale the position from [-1,1] to [0,1] for proper texture coords
• Sample the texture to be projected 

===============================================================================================================
TEXTURE COMPRESSION
===============================================================================================================

LOSSY COMPRESSION: Filesize over quality
LOSSLESS COMPRESSION: Quality over filesize
NORMAL COMPRESSION: Not recommended as compressing normal maps can un-normalize normals

RUN LENGTH ENCODING: 
• Lossless encoding
• aaabbccc ==> a3b2c3
• Problem is lots of 1 values and encoding doubles the size
• Solved by using a marker to indicate where encoding has happened
• Close colored pixels can be merged into the one color and counted in run

HUFFMAN ENCODING:
• Lossless encoding
• Uses binary tree/priority queue
  1) Find frequency of every character used
  2) Create a node for every character used and store in a priority queue
  3) Each node is sorted due to it's frequency number (least to greatest)
  4) The top two nodes with the smallest frequency are removed and put as children to a new node
  5) This new node is given a frequency that equals the combined children's frequency
  6) The new node is inserted into the priority queue
  7) Continue this until there is one large node left in the queue creates the tree
  8) Traverse through the graph (left gives 0, right gives 1)
  9) Store the path taken to the correct letter
  10) Create a Huffman table (array) to store the path information

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// DETAIL MAPPING
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

DETAIL MAPPING: Changes interpolated normal depending on map
INTERPOLATED NORMAL: Normal in pixel shader for specific pixel of surface; makes surface smooth
OBJECT SPACE MAPPING: Map is unique to specific object (rainbow)
TANGENT SPACE MAPPING: Map can be reused (purple/blue/red)

BUMP MAP
• Created from height map/grayscale image

NORMAL MAP
• Created from difference of high/low resolution mesh

PARALLAX MAP
• Creates illusion of depth by displacing UV coordinates
• Find view angle (angle relative to the surface normal) and value from a height map using UV coordinates
• Use both to calculate new UV coordinates to access tex2D information
• Steeper view-angles = more displacement giving illusion of depth as the view changes

DISPLACEMENT MAP
• Direction vector read from displacement map and added to vertex position moving it to another place

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// TRANSPARENCY
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

• Render non-transparent objects first in any order
• Render transparent objects back to front according to depth
• ALPHA BLENDING: blends alpha pixel into buffer using a set formula
• ALPHA TESTING: tests whether alpha pixel contributes to the colour buffer
• ALPHA TO COVERAGE: multisampling for transparency billboards (grass, foliage, trees etc)

 ------------------------------------------------------------------
| RESULT rgb = (SRCBLEND * SRCrgb) [BLENDOP] (DESTBLEND * DESTrgb) |
 ------------------------------------------------------------------
DESTrgb = pixel colour currently in buffer from previous rendering
SRCrgb = pixel colour being generated by shader

DEFAULT ALPHA BLENDING
AlphaBlendEnable = true
SrcBlend = SrcAlpha
DestBlend = InvSrcAlpha
BlendOp = Add

DEFAULT ALPHA TESTING
AlphaTestEnable = true;
AlphaFunc = GreaterEqual; (only accept if alpha >= 128)
AlphaRef = 128; 

BLENDOP
Add:          (SRCBLEND * SRCrgb) + (DESTBLEND * DESTrgb)
Subtract:     (SRCBLEND * SRCrgb) - (DESTBLEND * DESTrgb)
RevSubtract:  (DESTBLEND * DESTrgb) - (SRCBLEND * SRCrgb)
Min:          min(SRCBLEND * SRCrgb, DESTBLEND * DESTrgb)
Max:          max(SRCBLEND * SRCrgb, DESTBLEND * DESTrgb)

ALPHAFUNC
Never:        Don't accept pixel into buffer
LessEqual:    Only accept pixel into buffer if <= AlphaRef
Less:         Only accept pixel into buffer if < AlphaRef
GreaterEqual: Only accept pixel into buffer if >= AlphaRef
Greater:      Only accept pixel into buffer if > AlphaRef
Always:       Always add to pixel buffer

SRCBLEND / DSTBLEND
Zero           (0, 0, 0, 0)
One            (1, 1, 1, 1)
SrcColor       (Rˢ, Gˢ, Bˢ, Aˢ)
InvSrcColor    (1-Rˢ, 1-Gˢ, 1-Bˢ, 1-Aˢ)
SrcAlpha       (Aˢ, Aˢ, Aˢ, Aˢ)
InvSrcAlpha    (1-Aˢ, 1-Aˢ, 1-Aˢ, 1-Aˢ)
DestAlpha      (Aᵈ, Aᵈ, Aᵈ, Aᵈ)
InvDestAlpha   (1-Aᵈ, 1-Aᵈ, 1-Aᵈ, 1-Aᵈ)
DestColor      (Rᵈ, Gᵈ, Bᵈ, Aᵈ)
InvDestColor   (1-Rᵈ, 1-Gᵈ, 1-Bᵈ, 1-Aᵈ)
SrcAlphaSat    (f, f, f, 1) where f = min(Aˢ,1-Aᵈ)

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// STENCILING
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

if(ref & mask [operator] value & mask == true) { accept pixel }

NEVER:           Stencil test always fails
ALWAYS:          Stencil test always succeeds
LESS:            <
EQUAL:           ==
LESSEQUAL:       <=
GREATER:         >
NOTEQUAL:        !=
GREATEREQUAL:    >=                     

KEEP: Keep value currently in stencil buffer
ZERO: Specifies to set the stencil buffer entry to zero.
REPLACE: Replace the buffer entry with stencil-reference value
INCRSAT: Increment the stencil buffer entry, clamps to max
DECRSAT: Decrement the stencil buffer entry, clamps to 0
INVERT: Invert the bits of the buffer entry
INCR: Increment the buffer entry, wraps to 0 if goes over max 
DECR: Decrement the buffer entry, wraps to max if goes under 0

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// ANTI-ALIASING
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

SUPERSAMPLING / SUPERSAMPLE ANTI-ALIASING (SSAA) / FULL SCENE ANTI-ALIASING (FSAA)
• Anti aliases whole scene including alpha billboards
• Renders image at higher resolution and size and down samples with a filter

MULTISAMPLING / MULTISAMPLE ANTI-ALIASING (MSAA)
• Anti aliases only polygon edges, area between edges/textures not smoothed
• Requires adaptive version to anti-alias alpha billboards
• Renders image at same resolution on a larger surface
• Coverage-sampled anti-aliasing (CSAA): Nvidia MSAA 
• Custom-filter anti-aliasing (CFAA): AMD MSAA

POST PROCESSING ANTI-ALIASING
• Looks at final pixels and smoothes edges including alpha billboards
• Fast Approximate anti-aliasing (FXAA)
• Morphological anti-aliasing (MLAA)
• Enhanced Subpixel Morphological anti-aliasing (SMAA): less blurry than FXAA
• Temporal anti-aliasing (TXAA): reduces flickering in motion

ADAPTIVE SAMPLING PATTERN: 
• Each pixel is averaged with the pixel's around it

GRID SAMPLING PATTERN: 
• Use on final texture and blur pixels with sharp changes from neighbours

RANDOM SAMPLING PATTERN: 
• Randomly samples pixels around center pixel; some areas too little/too much this way

POISSON DISC SAMPLING PATTERN: 
• Random sampling with additional checks to whether samples are too close to each other

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// LIGHT TYPES
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

DIRECTIONAL LIGHTS 
• Direction only
• Used to represent broad light source at a distance, illuminating whole scene
• Light moves in one direction, hitting surfaces, no attenuation used
• Not affected by attenuation and range

POINT/OMNI LIGHTS 
• Position only
• Emits light from all directions
• Affected by attenuation and range

SPOT LIGHTS 
• Direction and Position
• Emits light in one direction that spreads out as distance increases
• Affected by falloff, attenuation, and range and uses theta/phi values
• Vertex position within inner or outer cone is determined to determine the brightness
• THETA VALUE: Radian angle of the spotlight's inner cone (brightest)
• PHI VALUE: Radian angle for the outer cone of light
• FALLOFF: Controls how light intensity decreases between the outer and inner cones; set as 1 for even

BLOOM LIGHTS
• Glow around an object that resembles a halo
• Occurs when eyes/camera suddenly views a very bright object

LENS FLARE
• Scattered light reflected from within the cameras lens

LIGHT SHAFTS
• Light scatters off particles suspended in the media (Dust, water vapour)
• Occurs when light enters/exits materials such as a window
• Draw polygons emitting from light source and use additive blending
• As polygon's vertices become more distant from light they become more transparent

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// LIGHTING
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

DIRECT LIGHTING
• Rays from a light that hit a surface directly
• Approximated by Shader Materials

INDIRECT LIGHTING
• Rays from a light that hit a surface indirectly, recieved from another surface
• Approximated by Ambient Lighting, Ambient Occlusion, Global Illumination etc

SURFACE MATERIALS
• When a photon hits a surface it can either go through:
    - Reflection
    - Transmission
    - Absorption
• Percentage of Reflection, Transmission and Absorption determined by:
    - Angle the light hits the surface
    - Index of Refraction (IOR) of the material
    - Type of material: Conductive Material (metal) or Dielectric (non-metal)

REFLECTION
• Types of reflection:
    - Specular/Surface reflection (very smooth surfaces)
        - Isotropic: evenly distributed
        - Anisotropic: stretched out perpendicular to the grooves in the surface
    - Diffuse/Subsurface reflection (rough surfaces)
• Selective reflection can be either specular or diffuse and tints the surface
    
TRANSMISSION
• Types of transmission:
    - Direct transmission (transparent)
    - Diffuse transmission (translucent)
• Selective transmission can be either direct or diffuse and tints the surface
• Diffuse reflection is actually transmission where the entry/exit points are almost identical
• Can cause Refraction:
    - Bending of light rays can occur when rays move in/out the surface
    - Amount of refraction determined by the Index of Refraction (IOR) of material
• Can cause Subsurface Scattering:
    - Light enters the material and bounces inside before leaving a different location
    - Some light is absorbed so leaves dimmer and slightly tinted

CONDUCTIVE MATERIALS (METALS)                   
• No diffuse reflection, only specular reflection 
• Can only have selective specular reflection
• Very minimal transmission

DIELECTRICS (NON-METALS)
• Both diffuse and specular reflection
• Can only have selective diffuse reflection
• Light that hits straight on most likely to go through transmission
• Light that hits at a glancing angle likely to go through reflection

BIDIRECTIONAL REFLECTANCE DISTRIBUTION FUNCTION (BRDF) 
• Describes how the material reflects or absorbs light from different angles
• Modelled by shaders (Lambert, Blinn, Phong, Ward etc)

FRESNAL SURFACES
• Display one colour when viewed straight on and a different colour at side angles
• Used for: 
    - Water shaders
    - Fade out reflections towards edges
    - Brighten edges
    - Make edges more transparent
    - Two tone colour mixing

INVERSE-SQUARE LIGHT FALLOFF (ATTENUATION): 
• Doubling the distance between the light and object results in 1/4 of the light hitting the object
• More distant the light is the less obvious the inverse-square light falloff
• Not used for sunlight as sun is too far away for noticable effect
• As light moves closer to specular reflection of an object the highlights appear bigger but not brighter

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// HIGH DYNAMIC RANGE RENDERING
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

LOW DYNAMIC RANGE (LDR): RGB values for pixels with range 0->1 of intensity for the display device
HIGH DYNAMIC RANGE (HDR): Values allowed outside 0->1 for colours/luminance visible to the human eye
TRICHROMATIC COLOR VALUES: Channels in an HDR image, also called radiance

1) Scene is rendered onto an HDR buffer allowing for values outside 0->1 range
2) HDR buffer is post-processed with effects such as HDR bloom/glow
3) HDR buffer goes through tone mapping to convert the values to LDR for displaying on the screen

ADVANTAGES
• Colors not being lost in high intensity areas
• Reduction of banding in low frequency lighting areas
• Artist gets control of intensity of colours depending on the scene lighting
• Better control of post processing effects:
    - LDR bloom/glow requires blurring itensities at a value < 1.0 which may blur undesirable areas
    - HDR bloom/glow allows for blurring areas in scene with intensity > 1.0
  
DISADVANTAGES
• Uses floating point render textures- rendering is slower and requires more VRAM
• No hardware anti-aliasing support

===============================================================================================================
TONEMAPPING
===============================================================================================================

TONEMAPPING OPERATORS   
• Process of mapping color values from HDR to LDR
• Maps HDR scene luminance into the luminance range that can be shown on a display
• Also called Gamma correction if the algorithm takes the display device into account
• Hundreds of algorithms, most famous is the Reinhard operator

sRGB COLOR SPACE
• Standard describing the relation between LDR pixel values and color emitted by the display
• Gamma value used for correction is 2.2

LUMINANCE
• Intensity of light emitted from a surface per unit area in a given direction
• From RGB: 0.2126 * R + 0.7152 * G + 0.0722 * B

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// SHADOWS
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

OCCLUDER: Any object in scene that casts shadows
UMBRA: Region that is completely in shadow and fully occluded
PENUMBRA: Area outside the umbra that gradually softens with distance
  
===============================================================================================================
SHADOW MAPPING
===============================================================================================================

CREATING SHADOW MAP
• Look at scene from point of view of light source 
• Create shadow map via writing scene depth to rendertarget from the light's perspective

USING SHADOW MAP
• Transform vertex by light view projection matrix to get position in light space
• If depth in shadow map is /w, make sure /w for position in pixel shader
• Compare this to the position saved in the shadow map (also in light space)
• If depth is further away than the depth in shadow map the object is in shadow of another object

ADVANTAGES:
• Cheaper to use
• Easy to blur and make into soft shadows

DISADVANTAGES:  
• Dependent on size/depth of shadow map
• Suffers from artefacts/aliasing problems
• Stitching artifacts:
    - Occurs when depth value of shadow is close to surface
    - Solved by offsetting the shadow depth value retrieved by an amount
    - Solved by turning on front-face cull when creating shadow map

===============================================================================================================
SHADOW PROJECTION
===============================================================================================================

• Shadow-projection matrix is created to scale anything rendered with it into a flat shape. 
• Light direction is used to control direction from which shadows appear once rendered. 
• The object is projected onto a plane then rendered as a separate primitive.

ADVANTAGES:     
• Easy to implement
• Doesn't require any hardware support such as shadow mapping
• Shadows can be created out of any object or an imposter can be used

DISADVANTAGES:  
• Doesn't work well on specular surfaces 
• Difficult with non-flat surfaces, stencil buffer fixes this
• Can't render self shadows
• Difficult to make into soft shadows
• Not a good representation of object
• z-fighting: 
    - close coplanar planes confuses the depth buffer for what to render first
    - Fixed by rendering at an offset or enabling hardware to take care of offset

===============================================================================================================
SHADOW VOLUMES
===============================================================================================================

• Project the outline of an object into the scene based on the light position. 
• New geometry is created using this silhouette.

PIPELINE:
• Find the edges of an object that define the silhouette and create edge list
• Calculate new geometry from edge list and light vector and store into its own vertex buffer
• Create a counter that will increment/decrement for every surface rendered to the stencil buffer
• Render scene with back-face culling on; increment for every surface rendered
• Render with front-face culling on; decrement for every surface rendered
• If an object is within a shadow volume after two stencil tests the stencil buffer will have 1, if not, 0
• Clear the screen to black
• Render scene normally using results to only render to screen pixels set to 0, leaving sections with 1 black

CARMAK'S REVERSE:
If camera is inside a shadow volume counting for stencil buffers can be incorrect. 
Pixels that should not be in shadow are considered in shadow. Solution:  
  • Render with front-face culling first and increment stencil buffer whenever depth test fails
  • Render with back-face culling second and decrement stencil buffer whenever depth test fails

ADVANTAGES:     
• No aliasing/artefact problems
• Can self shadow
• More accurate representation of model

DISADVANTAGES:  
• Geometry dependent/expensive
• Requires additional data for quick determination of silhouette (object edge list)
• Difficult to make into soft shadows

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// TERRAIN GENERATION
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

MIDPOINT DISPLACEMENT ALGORITHM
• Start with basic four vertex shape and slip by adding vertex in middle
• Get x/z values of middle vertex from midpoint of surrounding vertices
• Get y value of middle vertex from a value between -d/2 and d/2
• Continue to split new four faces multiplying d by 2^-r each time
• Filter to remove sharp transitions
• Smaller R = rougher terrain

FAULT FORMATION ALGORITHM
• Starts with grid for terrain and creates random line accross the terrain
• Raise vertices on one side of the line and lower on other by amount d
• Create another line and repeat, reducing d each pass
• More passes = rougher terrain

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// ANIMATION / VIDEO
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

PAL:  25fps     576 pixel lines  720 × 576
NTSC: 29.97fps  525 pixel lines  720 × 486

INTERLACE: for tvs to prevent shuttering artifacts, frame is split into two fields
PROGRESSIVE: frame is drawn top to bottom

3 POINT LIGHTING SETUP
• KEY LIGHT: Light source the scheme is built around; main provider of light
• FILL LIGHT: Helps control contrast by filling in dark shadows created by key light
• BACK LIGHT: Defines the edge around the subject and seperates them from background

DEPTH OF FIELD:
• Smaller iris opening in camera = less exposure and light entering = more depth of field
• Larger iris opening in camera = more exposure and light entering = less depth of field
• Wide angle/short focal length lens = greater DOF
• Narrow angle/long focal length lens = smaller DOF
• Subject far away = greater DOF
• Subject up close = smaller DOF

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// PRIMITIVES
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////

POINT LISTS:  .    .    . .   .
LINE LIST: ._________________. 
LINE STRIP: ._______._______.___._______._____.

TRIANGLE LISTS:
     __
    |\ | Triangle1 {1,2,3} Limitation is no sharing of vertices
    |_\| Triangle2 {3,4,1} which increases vertex count

TRIANGLE STRIPS: 
     ___
    |\ |\  Specify first four points then one
    |_\|_\ point for every new triangle in strip

TRIANGLE FANS:
     ____
    |\  /| All triangles connect
    | \/ | to a common point
    | /\ |
    |/__\|

CONVEX POLYGONS: line between two points in polygon never crosses border 
CONCAVE POLYGONS: line between two points in polygon can cross border
POLYHEDRA: three dimensional object with flat faces and straight edges
POLYTOPES: convex hulls of finite points sets (line segments, triangles, polyhedra)
QUADRICS: spheres, cones, cylinders