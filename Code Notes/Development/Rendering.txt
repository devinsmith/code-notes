///////////////////////////////////////////////////////////////////////////////////////////////////
//RENDER PIPELINE
///////////////////////////////////////////////////////////////////////////////////////////////////

TEXEL: One unit of a texture
PIXEL: One unit of the screen
FRAGMENT: Potential pixel. Each fragment has a pixel location, a depth value, color/texture values
HOMOGENEOUS CLIP SPACE: Screen space multiplied by 'w' component

01) FRUSTUM CULLING: Culls and creates list of meshes based on view frustum
02) INPUT ASSEMBLER: Reads index/vertex data of each mesh
03) VERTEX SHADER: Gets input vertex data, converts to homogenous clip space
04) HULL SHADER: Inputs patch primitives, writes patch control points
05) TESSELLATOR STAGE: Creates vertices and connectivity for tessellated lines or triangles.
06) DOMAIN SHADER: Takes shaded control points and outputs vertices
07) GEOMETRY SHADER: Inputs primitives optionally with adjacency information, then outputs different primitives
08) STREAM-OUT: Writes Geometry shader output to buffer in memory
09) BACKFACE CULLING: Face culling occurs depending on vert winding order
10) CLIPPING: Clips any vertices outside the visible screen (If x,y is in range [-w,w] and z is in range [0,w] then okay)
11) SCREEN MAPPING: Homogenous clip space transformed into screen space
12) RASTERIZATION: 2D shape fitted into pixels

    TRIANGLE TRAVERSAL:
     • If the center of pixel is enclosed in shape, pixel is fully filled. 
     • This creates a stepping, aliased effect. 
     • 2D object may visibly shift in position during this process

    FRAGMENT GENERATION:
    • Every pixel covered by shape is a Fragment. 
    • Fragment values are interpolated from the 2D triangles they're made up of

13) PIXEL SHADING: Gets interpolated vertex data as fragments, outputs pixel colors
14) OUTPUT MERGER: Gets shaded pixels from PS, does alpha blending and writes them back to the backbuffer.
15) TRANSPARENCY: If translucent objects, render after all opaque meshes in back to front order

=============================================================================================
FORWARD SHADING
=============================================================================================
• Renders lighting with diffuse pass
• Easy to render transparency
• Expensive to do post effects
• Are limited in amount of lights

1) Render the scene with any lights that affect it to a color buffer
2) Render the scene again for additional information or output to additional buffers in color pass
3) Perform any post effects and present final image to the back buffer

=============================================================================================
DEFERRED SHADING
=============================================================================================
• Defers lighting to its own pass
• Difficult to render transparecy
• Cheap to do post effects
• Can have many multiple lights

1) Render the scene once sending attributes to a G-buffer
   Attributes include: Normals, Depth, Diffuse, Specular, Ambient etc.
2) Render all lights as geometry with attenuation/intensity
   Point light: Sphere, Spot light: Cone, Directional light: Full screen quad
3) Combine the lighting texture with the G-buffer calculating the color 
   contribution of the light to the final pixel
4) Perform any post effects with the ability to use the G-buffer

///////////////////////////////////////////////////////////////////////////////////////////////////
//GRAPHICS BUFFERS
///////////////////////////////////////////////////////////////////////////////////////////////////

FORMAT: Describes the layout of the resource’s data in memory
PAGE FLIPPING: Double buffering to prevent tearing
FRAMEBUFFER/RASTER: Array of memory addresses representing pixels
DEFAULT BACK/FRONT BUFFERS: 32bit color buffer

DEPTH/Z BUFFER
• Saves projected depths of models from viewer (0.0->1.0)
• Needs to be same size or larger than connected color buffer
• Writing to can be turned on/off (ZWRITEENABLE) and affected by comparion function

DEPTH BUFFER COMPARISON FUNCTION
• Discards the incoming fragment if a depth comparison fails
• ZFunc = Never         Don't add to depth buffer
• ZFunc = LessEqual     Only add if depth value <= current value in buffer
• ZFunc = Less          Only add if depth value < current value in buffer
• ZFunc = GreaterEqual  Only add if depth value >= current value in buffer
• ZFunc = Greater       Only add if depth value > current value in buffer
• ZFunc = Always        Always add to depth buffer

DEPTH BUFFER ACCURACY
• Inaccuracy causes z-fighting where triangles have same value in buffer
• Accuracy dependent on:
    - Buffer storage size (32 or 16 bits)
    - Distance between near/far planes
    - Distance between near/origin
• Near getting closer to origin gives less accuracy to values close to far plane
• Near-far distance increasing gives less accuracy to values close to far plane
• Objects together close to far plane z values may be rounded as same value since more 
  of buffer is used for objects closer to near due to non-linear scaling into the buffer
    
STENCIL BUFFER
• masks areas during rendering; specifies what's hidden/shown
• Holds on/off flag

ATTRIBUTE BUFFER
• Buffer of integers
• Used to specify which triangles belong to each subset of a mesh with 
  multiple parts (01120 means triangle 1 belongs to subset 0, triangle 
  2 belongs to subset 1 etc.)

RENDER TARGETS
• Comprised of a color buffer and a depth/stencil buffer 

///////////////////////////////////////////////////////////////////////////////////////////////////
//TRANSPARENCY
///////////////////////////////////////////////////////////////////////////////////////////////////

• Render non-transparent objects first in any order
• Render transparent objects back to front according to depth
• Alpha blending: blends alpha pixel into buffer using a set formula
• Alpha testing: tests whether alpha pixel contributes to the colour buffer
• Alpha to coverage: multisampling for transparency billboards (grass, foliage, trees etc)

-----------------------------------------------------------------
RESULT rgb = (SRCBLEND * SRCrgb) [BLENDOP] (DESTBLEND * DESTrgb)
-----------------------------------------------------------------
DESTrgb = pixel colour currently in buffer from previous rendering
SRCrgb = pixel colour being generated by shader

DEFAULT ALPHA BLENDING
AlphaBlendEnable = true
SrcBlend = SrcAlpha
DestBlend = InvSrcAlpha
BlendOp = Add

DEFAULT ALPHA TESTING
AlphaTestEnable = true;
AlphaFunc = GreaterEqual; (only accept if alpha >= 128)
AlphaRef = 128; 

BLENDOP
Add:          (SRCBLEND * SRCrgb) + (DESTBLEND * DESTrgb)
Subtract:     (SRCBLEND * SRCrgb) - (DESTBLEND * DESTrgb)
RevSubtract:  (DESTBLEND * DESTrgb) - (SRCBLEND * SRCrgb)
Min:          min(SRCBLEND * SRCrgb, DESTBLEND * DESTrgb)
Max:          max(SRCBLEND * SRCrgb, DESTBLEND * DESTrgb)

ALPHAFUNC
Never:        Don't accept pixel into buffer
LessEqual:    Only accept pixel into buffer if <= AlphaRef
Less:         Only accept pixel into buffer if < AlphaRef
GreaterEqual: Only accept pixel into buffer if >= AlphaRef
Greater:      Only accept pixel into buffer if > AlphaRef
Always:       Always add to pixel buffer

SRCBLEND / DSTBLEND
Zero           (0, 0, 0, 0)
One            (1, 1, 1, 1)
SrcColor       (Rˢ, Gˢ, Bˢ, Aˢ)
InvSrcColor    (1-Rˢ, 1-Gˢ, 1-Bˢ, 1-Aˢ)
SrcAlpha       (Aˢ, Aˢ, Aˢ, Aˢ)
InvSrcAlpha    (1-Aˢ, 1-Aˢ, 1-Aˢ, 1-Aˢ)
DestAlpha      (Aᵈ, Aᵈ, Aᵈ, Aᵈ)
InvDestAlpha   (1-Aᵈ, 1-Aᵈ, 1-Aᵈ, 1-Aᵈ)
DestColor      (Rᵈ, Gᵈ, Bᵈ, Aᵈ)
InvDestColor   (1-Rᵈ, 1-Gᵈ, 1-Bᵈ, 1-Aᵈ)
SrcAlphaSat    (f, f, f, 1) where f = min(Aˢ,1-Aᵈ)

///////////////////////////////////////////////////////////////////////////////////////////////////
//STENCILING
///////////////////////////////////////////////////////////////////////////////////////////////////

if(ref & mask [operator] value & mask == true) { accept pixel }

NEVER:           Stencil test always fails
ALWAYS:          Stencil test always succeeds
LESS:            <
EQUAL:           ==
LESSEQUAL:       <=
GREATER:         >
NOTEQUAL:        !=
GREATEREQUAL:    >=                     

KEEP: Keep value currently in stencil buffer
ZERO: Specifies to set the stencil buffer entry to zero.
REPLACE: Replace the buffer entry with stencil-reference value
INCRSAT: Increment the stencil buffer entry, clamps to max
DECRSAT: Decrement the stencil buffer entry, clamps to 0
INVERT: Invert the bits of the buffer entry
INCR: Increment the buffer entry, wraps to 0 if goes over max 
DECR: Decrement the buffer entry, wraps to max if goes under 0

///////////////////////////////////////////////////////////////////////////////////////////////////
//TRANSFORMATIONS
///////////////////////////////////////////////////////////////////////////////////////////////////

----------------
|  YAW:    Y   |
|  PITCH:  X   |
|  ROLL:   Z   |
----------------

EULER ANGLES
• Set of pitch, roll, yaw combined to form a matrix
• Suffer from gimbal lock
• Less storage space needed (3 values)

MATRICES: 
• Suffer from gimbal lock if used with Euler Angles
• More storage space needed (12 values)
• Slow, rounding errors

QUATERNIONS: 
• No Gimbal lock
• Less storage space needed (4 values)
• Fast, less rounding errors

GIMBAL LOCK
• A set of three gimbals mounted together to allow three degrees of freedom
• If the middle gimbal is rotated greater than 90, the top and bottom gimbals 
  are aligned and in gimbal lock losing a degree of freedom. 

VIEW MATRIX
• Inverse of the Camera World Matrix
• changes the world scene basis so the camera is at the origin

///////////////////////////////////////////////////////////////////////////////////////////////////
//PROJECTION
///////////////////////////////////////////////////////////////////////////////////////////////////

VIEW FRUSTUM:
Pyramid volume from camera to world, has near and front clipping planes

ORTHOGONAL PROJECTION MATRIX:
objects remain same size regardless of depth

PERSPECTIVE PROJECTION MATRIX:
objects different sizes according to depth, uses horizon as vanishing point 

D3DXMatrixPerspectiveFovLH(&projectionMatrix,
                           D3DX_PI/2,    //field of view (α)
                           Width/height  //aspect ratio (R)
                           10.0f,        //z-value of the near view-plane (n)
                           1000.0f);     //z-value of the far view-plane (f)

PROJECTING VERTS INTO SCREEN SPACE:
For view space coordinates x,y positions need to be between [-1,1]
For view space coordinate z, depth needs to be between [0,-1]

tan(b/2) = R*tan(α/2)
tan(b/2)*n = W/2
tan(α/2)*n = H/2

 A = 1/(R*tan(α/2))
 B = 1/(R*tan(b/2))
 C = f/(f-n)
 D = -fn/(f-n)

         | A 0 0 0 |
[x y z 1]| 0 B 0 0 | = [Ax By (Cz+D)  z]
         | 0 0 C 1 |   HOMOGENEOUS CLIP SPACE
         | 0 0 D 0 |
         PROJ MATRIX

In homogeneous clip space: culling/clipping
If x,y is in range [-w,w] and z is in range [0,w] then okay
To get final coordinate, divide by w (which is screen space z)

[x' y' z' 1] = [Ax/z  By/z  C+(D/z)  1]
 --------------------------------------
| x' = x/(zRtan(α/2))        = Ax/z    |
| y' = y/(ztan(α/2))         = By/z    |
| z' = (f/f-n)-(fn/(z(f-n))) = C+(D/z) |
 --------------------------------------

///////////////////////////////////////////////////////////////////////////////////////////////////
//OPTIMISATION
///////////////////////////////////////////////////////////////////////////////////////////////////

FARPLANE CULLING
• Any objects past the farplane are culled
• Limitation is if plane is too close objects seen disappearing
• This can be fixed by using fog to hide far distances

FRUSTUM CULLING
• Only objects in frustum are drawn. 
• If Polygon outside it's not visible and hence discarded
• If partially inside its clipped so outside parts are removed

FRONT/BACKFACE CULLING
• Winding order of vertices indicates which way polygon is facing

CLIPPING
• Any screen space coordinates outside [–1,–1,0] to [1,1,1] culled

OCCLUSION CULLING
• Identifies parts of the scene visible/not visible to the viewer
• Objects behind other objects are discarded
• Can use a plane to represent occluder (similar to frustum culling)
• Can use Potential Visible Sets for indoor scenes

OPTIMIZATION TIPS
• Don't allocate stencil if you don’t use it
• R5G6B5 color sufficient for dynamic reflection maps
• Use low resolution (<256x256) 8-bit normalization cube-maps
• Use half instead of float where strict precision isn't important
• Render a depth-only pass before color pass to reduce pixel shader use

///////////////////////////////////////////////////////////////////////////////////////////////////
//COLOUR
///////////////////////////////////////////////////////////////////////////////////////////////////

8bit   RGB:  Only 256 colors to use
24bit  RGB:  Each channel has 8bits (256 colors)
32bit  ARGB: Each channel has 8bits (256 colors) including 8bit alpha channel

HSB (Hue/Saturation/Brightness)        Cylindrical colour representation
CMYK (Cyan/Magenta/Yellow/Key[Black])  Subtractive colour model
RGB (Red/Green/Blue)                   Additive colour model

HUE = Particular colour in rainbow
SATURATION = How rich a colour is
VALUE = How much Black/White a colour has
TINTS = Saturation decreases
SHADES = Value decreases
TONES = Saturation/Value decreases

COLOUR BLENDING
• Linear blending loses saturation between colours
• Blending must occur in polar coordinate space to maintain saturation
• Polar coordinate space: HSV/HSB, CIE-Lab
• Note add primary colour = 6 check to primary colour = 0 when blending hues

///////////////////////////////////////////////////////////////////////////////////////////////////
//TEXTURES
///////////////////////////////////////////////////////////////////////////////////////////////////

TGA = Targa
PNG = Portable Network Graphics
JPEG = Joint Photography Experts Group
BMP = Bitmap
GIF = Graphics Interchange Format

SANS-SERIF FONT: rounded edges of characters
SERIF FONT: little lines on edges of characters

TEXTURE MAPPING: UV coordinates for 2D image
CUBE MAPPING: UVW coordinates for 3D cube image
MINFILTER: Texture filter used when shrinking textures
MAGFILTER: Texture filter used when magnifying textures

POINT FILTERING: 
• Nearest Neighbour/Box Filtering
• Nearest texel is chosen to the given UV coordinates
• If coordinates are on texel border, UVs are rounded

LINEAR FILTERING:
• Bilinear/Trilinear filtering
• Looks at 2x2 texels surrounding the UVs and calculates color using weights
• If UVs totally in one texel: 100% that texel
• If UVs on border between two texels: 50% each
• If UVS on border between four texels: 25% each
• Trilinear: Fixes artifact occurs when stitching various mipmap levels together

ANISOTROPIC FILTERING: 
• Most consuming of all filters
• Avoids blur at sharp angles/distances
• Prevents distortion when angle between camera forward vector and poly normal is large

MIPMAP:
• Mip = multum in parvo; 'many things in a small place'
• Series of power of 2 texture created from original texture

MIPFILTER:
• None disables mipmapping
• Point chooses mipmap level that is closest in size to geometry and filter
• Linear chooses Two mipmap levels that are closest in size to geometry then
  filter both and lineraly combine them

PROJECTIVE TEXTURING:
• Method of projecting a texture into a 3D scene
• Transform local position of vert by light's worldViewProj matrix
• Pass position to pixel shader
• Position will be in homogenous clip space so divide by w
• Scale the position from [-1,1] to [0,1] for proper texture coords
• Sample the texture to be projected 

GAMMA CORRECTION
• the relationship between a pixel's numerical value and its actual luminance

SRGB COLOR SPACE
• Texture blending operations are done in linear space
• sRGB format is gamma corrected color which produce incorrect results in linear space

///////////////////////////////////////////////////////////////////////////////////////////////////
//TEXTURE COMPRESSION
///////////////////////////////////////////////////////////////////////////////////////////////////

LOSSY COMPRESSION: Filesize over quality
LOSSLESS COMPRESSION: Quality over filesize
NORMAL COMPRESSION: Compressions not recommended since compressing normal 
                    maps can un-normalize normals

===========================================================================
RUN LENGTH ENCODING: 
===========================================================================
• lossless encoding
• aaabbccc ==> a3b2c3
• problem is lots of 1 values and encoding doubles the size
• solved by using a marker to indicate where encoding has happened
• close colored pixels can be merged into the one color and counted in run

===========================================================================
HUFFMAN ENCODING:
===========================================================================
• lossless encoding
• uses binary tree/priority queue

1) Find frequency of every character used
2) Create a node for every character used and store in a priority queue
3) Each node is sorted due to it's frequency number (least to greatest)
4) The top two nodes with the smallest frequency are removed and put as children to a new node
5) This new node is given a frequency that equals the combined children's frequency
6) The new node is inserted into the priority queue
7) Continue this until there is one large node left in the queue creates the tree
8) Traverse through the graph (left gives 0, right gives 1) and store the path taken to the correct letter
9) Create a Huffman table (array) to store the path information

///////////////////////////////////////////////////////////////////////////////////////////////////
//DETAIL MAPPING
///////////////////////////////////////////////////////////////////////////////////////////////////

DETAIL MAPPING: Changes interpolated normal depending on map
INTERPOLATED NORMAL: Normal in pixel shader for specific pixel of surface; makes surface smooth
OBJECT SPACE MAPPING: Map is unique to specific object (rainbow)
TANGENT SPACE MAPPING: Map can be reused (purple/blue/red)

BUMP MAP
• Created from height map/grayscale image

NORMAL MAP
• Created from difference of high/low resolution mesh

PARALLAX MAP
• Creates illusion of depth by displacing UV coordinates
• Find view angle (angle relative to the surface normal) and value from a height map using UV coordinates
• Use both to calculate new UV coordinates to access tex2D information
• Steeper view-angles = more displacement giving illusion of depth as the view changes

DISPLACEMENT MAP
• Direction vector read from displacement map and added to vertex position moving it to another place

///////////////////////////////////////////////////////////////////////////////////////////////////
//ANTIALIASING
///////////////////////////////////////////////////////////////////////////////////////////////////

 -------------------------------------------------------------
| FINAL PIXEL += WEIGHTING * SAMPLED PIXEL AROUND FINAL PIXEL |
 -------------------------------------------------------------

===========================================================================
TECHNIQUES
===========================================================================

DOWNSAMPLING/FULL SCENE ANTIALIASING (FSAA): 
• Renders at an increased resolution and resizes down
• By doubling screen size you get 4 samples per pixel

ACCUMULATION BUFFER METHOD
• Screen is rendered 4 times each with view moved by half a pixel in x/y
• Screens summed up in accumulation buffer and averaged (/4)

MULTISAMPLING
• Optimized supersampling where some components are not supersampled
• Downside is edges of alpha objects are still aliased

===========================================================================
SAMPLING PATTERNS
===========================================================================

ADAPTIVE SAMPLING: 
• Each pixel is averaged with the pixel's around it

GRID SAMPLING: 
• Use on final texture and blur pixels with sharp changes from neighbours

RANDOM SAMPLING: 
• Randomly samples pixels around center pixel; some areas too little/too much this way

POISSON DISC SAMPLING: 
• Random sampling with additional checks to whether samples are too close to each other

///////////////////////////////////////////////////////////////////////////////////////////////////
//LIGHT TYPES
///////////////////////////////////////////////////////////////////////////////////////////////////

DIRECTIONAL LIGHTS 
• Direction only
• Used to represent broad light source at a distance, illuminating whole scene
• Light moves in one direction, hitting surfaces, no attenuation used
• Not affected by attenuation and range

POINT/OMNI LIGHTS 
• Position only
• Emits light from all directions
• Affected by attenuation and range

SPOT LIGHTS 
• Direction and Position
• Emits light in one direction that spreads out as distance increases
• Affected by falloff, attenuation, and range and uses theta/phi values
• Vertex position within inner or outer cone is determined to determine the brightness
• THETA VALUE: Radian angle of the spotlight's inner cone (brightest)
• PHI VALUE: Radian angle for the outer cone of light
• FALLOFF: Controls how light intensity decreases between the outer and inner cones; set as 1 for even

BLOOM LIGHTS
• Glow around an object that resembles a halo
• Occurs when eyes/camera suddenly views a very bright object

LENS FLARE
• Scattered light reflected from within the cameras lens

LIGHT SHAFTS
• Light scatters off particles suspended in the media (Dust, water vapour)
• Occurs when light enters/exits materials such as a window
• Draw polygons emitting from light source and use additive blending
• As polygon's vertices become more distant from light they become more transparent

///////////////////////////////////////////////////////////////////////////////////////////////////
//LIGHTING
///////////////////////////////////////////////////////////////////////////////////////////////////

DIRECT LIGHTING
• Rays from a light that hit a surface directly
• Approximated by Shader Materials

INDIRECT LIGHTING
• Rays from a light that hit a surface indirectly, recieved from another surface
• Approximated by Ambient Lighting, Ambient Occlusion, Global Illumination etc

SURFACE MATERIALS
• When a photon hits a surface it can either go through:
    - Reflection
    - Transmission
    - Absorption
• Percentage of Reflection, Transmission and Absorption determined by:
    - Angle the light hits the surface
    - Index of Refraction (IOR) of the material
    - Type of material: Conductive Material (metal) or Dielectric (non-metal)

REFLECTION
• Types of reflection:
    - Specular/Surface reflection (very smooth surfaces)
        - Isotropic: evenly distributed
        - Anisotropic: stretched out perpendicular to the grooves in the surface
    - Diffuse/Subsurface reflection (rough surfaces)
• Selective reflection can be either specular or diffuse and tints the surface
    
TRANSMISSION
• Types of transmission:
    - Direct transmission (transparent)
    - Diffuse transmission (translucent)
• Selective transmission can be either direct or diffuse and tints the surface
• Diffuse reflection is actually transmission where the entry/exit points are almost identical
• Can cause Refraction:
    - Bending of light rays can occur when rays move in/out the surface
    - Amount of refraction determined by the Index of Refraction (IOR) of material
• Can cause Subsurface Scattering:
    - Light enters the material and bounces inside before leaving a different location
    - Some light is absorbed so leaves dimmer and slightly tinted

CONDUCTIVE MATERIALS (METALS)                   
• No diffuse reflection, only specular reflection 
• Can only have selective specular reflection
• Very minimal transmission

DIELECTRICS (NON-METALS)
• Both diffuse and specular reflection
• Can only have selective diffuse reflection
• Light that hits straight on most likely to go through transmission
• Light that hits at a glancing angle likely to go through reflection

BIDIRECTIONAL REFLECTANCE DISTRIBUTION FUNCTION (BRDF) 
• Describes how the material reflects or absorbs light from different angles
• Modelled by shaders (Lambert, Blinn, Phong, Ward etc)

FRESNAL SURFACES
• Display one colour when viewed straight on and a different colour at side angles
• Used for: 
    - Water shaders
    - Fade out reflections towards edges
    - Brighten edges
    - Make edges more transparent
    - Two tone colour mixing

INVERSE-SQUARE LIGHT FALLOFF (ATTENUATION): 
• Doubling the distance between the light and object results in 1/4 of the light hitting the object
• More distant the light is the less obvious the inverse-square light falloff
• Not used for sunlight as sun is too far away for noticable effect
• As light moves closer to specular reflection of an object the highlights appear bigger but not brighter

///////////////////////////////////////////////////////////////////////////////////////////////////
//HIGH DYNAMIC RANGE (HDR) LIGHTING
///////////////////////////////////////////////////////////////////////////////////////////////////

LUMINANCE
Intensity of light per unit area of its source

TONE MAPPING
Maps the high dynamic range (HDR) of luminance values of real world lighting
to the limited range of the screen by dividing scene into set of zones.
  • Zone: range of luminance values
  • Middle gray: middle brightness region of the scene
  • Dynamic range: ratio of the highest scene luminance to the lowest scene luminance
  • Key: subjective measurement of scene lighting varying from light to dark

///////////////////////////////////////////////////////////////////////////////////////////////////
//SHADOWS
///////////////////////////////////////////////////////////////////////////////////////////////////

OCCLUDER: Any object in scene that casts shadows
UMBRA: Region that is completely in shadow and fully occluded
PENUMBRA: Area outside the umbra that gradually softens with distance
  
==================================================================================================
SHADOW MAPPING
==================================================================================================

CREATING SHADOW MAP
• Look at scene from point of view of light source 
• Create shadow map via writing scene depth to rendertarget from the light's perspective

USING SHADOW MAP
• Transform vertex by light view projection matrix to get position in light space
• If depth in shadow map is /w, make sure /w for position in pixel shader
• Compare this to the position saved in the shadow map (also in light space)
• If depth is further away than the depth in shadow map the object is in shadow of another object

ADVANTAGES:
• Cheaper to use
• Easy to blur and make into soft shadows

DISADVANTAGES:  
• Dependent on size/depth of shadow map
• Suffers from artefacts/aliasing problems
• Stitching artifacts:
    - Occurs when depth value of shadow is close to surface
    - Solved by offsetting the shadow depth value retrieved by an amount
    - Solved by turning on front-face cull when creating shadow map

==================================================================================================
SHADOW PROJECTION
==================================================================================================

• Shadow-projection matrix is created to scale anything rendered with it into a flat shape. 
• Light direction is used to control direction from which shadows appear once rendered. 
• The object is projected onto a plane then rendered as a separate primitive.

ADVANTAGES:     
• Easy to implement
• Doesn't require any hardware support such as shadow mapping
• Shadows can be created out of any object or an imposter can be used

DISADVANTAGES:  
• Doesn’t work well on specular surfaces 
• Difficult with non-flat surfaces, stencil buffer fixes this
• Can’t render self shadows
• Difficult to make into soft shadows
• Not a good representation of object
• z-fighting: 
    - close coplanar planes confuses the depth buffer for what to render first
    - Fixed by rendering at an offset or enabling hardware to take care of offset

==================================================================================================
SHADOW VOLUMES
==================================================================================================

• Project the outline of an object into the scene based on the light position. 
• New geometry is created using this silhouette.

PIPELINE:
• Find the edges of an object that define the silhouette and create edge list
• Calculate new geometry from edge list and light vector and store into its own vertex buffer
• Create a counter that will increment/decrement for every surface rendered to the stencil buffer
• Render scene with back-face culling on; increment for every surface rendered
• Render with front-face culling on; decrement for every surface rendered
• If an object is within a shadow volume after two stencil tests the stencil buffer will have 1, if not, 0
• Clear the screen to black
• Render scene normally using results to only render to screen pixels set to 0, leaving sections with 1 black

CARMAK'S REVERSE:
If camera is inside a shadow volume counting for stencil buffers can be incorrect. 
Pixels that should not be in shadow are considered in shadow. Solution:  
  • Render with front-face culling first and increment stencil buffer whenever depth test fails
  • Render with back-face culling second and decrement stencil buffer whenever depth test fails

ADVANTAGES:     
• No aliasing/artefact problems
• Can self shadow
• More accurate representation of model

DISADVANTAGES:  
• Geometry dependent/expensive
• Requires additional data for quick determination of silhouette (object edge list)
• Difficult to make into soft shadows
 
==================================================================================================
SOFT SHADOWS
==================================================================================================

SHADOW MAP: 
• Render only shadows from the shadow map onto a surface and blur using a bloom filter
• Scene rendered again blending the soft shadows into the scene

SHADOW PROJECTION/VOLUME:
• Use two objects: One for the umbra and one for penumbra, fading out penumbra 
• Jittering: Render the shadow more than once, each time in a 
  different position and blend with previous renders

///////////////////////////////////////////////////////////////////////////////////////////////////
//TERRAIN GENERATION
///////////////////////////////////////////////////////////////////////////////////////////////////

MIDPOINT DISPLACEMENT ALGORITHM
• Start with basic four vertex shape and slip by adding vertex in middle
• Get x/z values of middle vertex from midpoint of surrounding vertices
• Get y value of middle vertex from a value between -d/2 and d/2
• Continue to split new four faces multiplying d by 2^-r each time
• Filter to remove sharp transitions
• Smaller R = rougher terrain

FAULT FORMATION ALGORITHM
• Starts with grid for terrain and creates random line accross the terrain
• Raise vertices on one side of the line and lower on other by amount d
• Create another line and repeat, reducing d each pass
• More passes = rougher terrain

///////////////////////////////////////////////////////////////////////////////////////////////////
//ANIMATION / VIDEO
///////////////////////////////////////////////////////////////////////////////////////////////////

PAL:  25fps     576 pixel lines  720 × 576
NTSC: 29.97fps  525 pixel lines  720 × 486
INTERLACE: for tvs to prevent shuttering artifacts, frame is split into two fields
PROGRESSIVE: frame is drawn top to bottom

3 POINT LIGHTING SETUP
• KEY LIGHT: Light source the scheme is built around; main provider of light
• FILL LIGHT: Helps control contrast by filling in dark shadows created by key light
• BACK LIGHT: Defines the edge around the subject and seperates them from background

DEPTH OF FIELD:
• Smaller iris opening in camera = less exposure and light entering = more depth of field
• Larger iris opening in camera = more exposure and light entering = less depth of field
• Wide angle/short focal length lens = greater DOF
• Narrow angle/long focal length lens = smaller DOF
• Subject far away = greater DOF
• Subject up close = smaller DOF

///////////////////////////////////////////////////////////////////////////////////////////////////
//PRIMITIVES
///////////////////////////////////////////////////////////////////////////////////////////////////

POINT LISTS:  .    .    . .   .
LINE LIST: ._________________. 
LINE STRIP: ._______._______.___._______._____.

TRIANGLE LISTS:
     __
    |\ | Triangle1 {1,2,3} Limitation is no sharing of vertices
    |_\| Triangle2 {3,4,1} which increases vertex count

TRIANGLE STRIPS: 
     ___
    |\ |\  Specify first four points then one
    |_\|_\ point for every new triangle in strip

TRIANGLE FANS:
     ____
    |\  /| All triangles connect
    | \/ | to a common point
    | /\ |
    |/__\|

CONVEX POLYGONS: line between two points in polygon never crosses border 
CONCAVE POLYGONS: line between two points in polygon can cross border
POLYHEDRA: three dimensional object with flat faces and straight edges
POLYTOPES: convex hulls of finite points sets (line segments, triangles, polyhedra)
QUADRICS: spheres, cones, cylinders