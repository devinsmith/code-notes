///////////////////////////////////////////////////////////////////////////////////////////////////
//RENDERING
///////////////////////////////////////////////////////////////////////////////////////////////////

RAYTRACING      [PRE-RENDER]        Casts rays from light to scene to view
RAYCASTING      [REALTIME-RENDER]   Casts rays from view to scene to light
RASTERIZATION   [REALTIME-RENDER]   Projects to plane using proj matrix

FORWARD RAY-TRACING [RAY TRACING]
• Rays traced from light into 3D scene
• Calculates new direction of rays when hitting surface
• Ideal for reflections/refractions
• Quality increases with more rays
• Disadvantage: hard to optimise, not possible in real time
• Disadvantage: lots of wasted rays that won't hit objects

BACKWARD RAY-TRACING [RAY CASTING]
• Rays traced from camera into 3D scene
• Does not compute new direction a ray takes after reflections/refractions
• Ray sent for each pixel; number of rays depends on screen resolution
• Every pixel will always be shaded; less rays/faster than raytracing

SCANLINE RENDERING [RASTERIZATION]
• Algorithm for determining which models are visible. 
• It goes row by row for pixels rather than look at each polygon.
• Polygons are sorted by their y coordinate and then intersected with a scanline
• Polygons obstructed by others are discards as the line advances down the image
• Only vertices needed for current scanline are worked on, speeding up process

PATH TRACING [RAY TRACING]
• Extends rays tracing where new rays are created/traced for object intersection points
• Takes into account indirect lighting/global illumination 

///////////////////////////////////////////////////////////////////////////////////////////////////
RENDER PIPELINE
///////////////////////////////////////////////////////////////////////////////////////////////////

TEXEL: One unit of a texture
PIXEL: One unit of the screen
FRAGMENT: Potential pixel. Each fragment has a pixel location, a depth value, color/texture values
HOMOGENEOUS CLIP SPACE: Screen space multiplied by 'w' component

01) FRUSTUM CULLING: Culls and creates list of meshes based on view frustum
02) INPUT ASSEMBLER: Reads index/vertex data of each mesh
03) VERTEX SHADER: Gets input vertex data, converts to homogenous clip space
04) HULL SHADER: Inputs patch primitives, writes patch control points
05) TESSELLATOR STAGE: Creates vertices and connectivity for tessellated lines or triangles.
06) DOMAIN SHADER: Takes shaded control points and outputs vertices
07) GEOMETRY SHADER: Inputs primitives optionally with adjacency information, then outputs different primitives
08) STREAM-OUT: Writes Geometry shader output to buffer in memory
09) BACKFACE CULLING: Face culling occurs depending on vert winding order
10) CLIPPING: Clips any vertices outside the visible screen (If x,y is in range [-w,w] and z is in range [0,w] then okay)
11) SCREEN MAPPING: Homogenous clip space transformed into screen space
12) RASTERIZATION: 2D shape fitted into pixels

    TRIANGLE TRAVERSAL:
     • If the center of pixel is enclosed in shape, pixel is fully filled. 
     • This creates a stepping, aliased effect. 
     • 2D object may visibly shift in position during this process

    FRAGMENT GENERATION:
    • Every pixel covered by shape is a Fragment. 
    • Fragment values are interpolated from the 2D triangles they're made up of

13) PIXEL SHADING: Gets interpolated vertex data as fragments, outputs pixel colors
14) OUTPUT MERGER: Gets shaded pixels from PS, does alpha blending and writes them back to the backbuffer.
15) TRANSPARENCY: If translucent objects, render after all opaque meshes in back to front order

==============================================================================
FORWARD SHADING
==============================================================================
• Easy to render transparency
• Expensive to do post effects
• Are limited in amount of lights

1) Render the scene with any lights that affect it to a single color buffer
2) Render the scene again outputting any information needed for post effects
3) Perform any post effects and present final image to the back buffer

==============================================================================
DEFERRED SHADING
==============================================================================
• Difficult to render transparecy
• Cheap to do post effects
• Can have many multiple lights

1) Render the scene once sending attributes to a G-buffer
   Attributes include: Normals, Depth, Diffuse, Specular, Ambient etc.
2) Render all lights as geometry with attenuation/intensity
   Point light: Sphere, Spot light: Cone, Directional light: Full screen quad
3) Combine the lighting texture with the G-buffer calculating the color 
   contribution of the light to the final pixel
4) Perform any post effects with the ability to use the G-buffer

///////////////////////////////////////////////////////////////////////////////////////////////////
//GRAPHICS BUFFERS
///////////////////////////////////////////////////////////////////////////////////////////////////

FORMAT: Describes the layout of the resource’s data in memory
PAGE FLIPPING: Double buffering to prevent tearing
FRAMEBUFFER/RASTER: Array of memory addresses representing pixels
DEFAULT BACK/FRONT BUFFERS: 32bit color buffer

DEPTH/Z BUFFER
• Saves projected depths of models from viewer (0.0->1.0)
• Needs to be same size or larger than connected color buffer
• Writing to can be turned on/off (ZWRITEENABLE) and affected by comparion function

DEPTH BUFFER COMPARISON FUNCTION
• Discards the incoming fragment if a depth comparison fails
• ZFunc = Never         Don't add to depth buffer
• ZFunc = LessEqual     Only add if depth value <= current value in buffer
• ZFunc = Less          Only add if depth value < current value in buffer
• ZFunc = GreaterEqual  Only add if depth value >= current value in buffer
• ZFunc = Greater       Only add if depth value > current value in buffer
• ZFunc = Always        Always add to depth buffer

DEPTH BUFFER ACCURACY
• Inaccuracy causes z-fighting where triangles have same value in buffer
• Accuracy dependent on:
    - Buffer storage size (32 or 16 bits)
    - Distance between near/far planes
    - Distance between near/origin
• Near getting closer to origin gives less accuracy to values close to far plane
• Near-far distance increasing gives less accuracy to values close to far plane
• Objects together close to far plane z values may be rounded as same value since more 
  of buffer is used for objects closer to near due to non-linear scaling into the buffer
    
STENCIL BUFFER
• masks areas during rendering; specifies what's hidden/shown
• Holds on/off flag

ATTRIBUTE BUFFER
• Buffer of integers
• Used to specify which triangles belong to each subset of a mesh with 
  multiple parts (01120 means triangle 1 belongs to subset 0, triangle 
  2 belongs to subset 1 etc.)

RENDER TARGETS
• Comprised of a color buffer and a depth/stencil buffer 

///////////////////////////////////////////////////////////////////////////////////////////////////
//TRANSPARENCY
///////////////////////////////////////////////////////////////////////////////////////////////////

• Render non-transparent objects first in any order
• Render transparent objects back to front according to depth
• Alpha blending: blends alpha pixel into buffer using a set formula
• Alpha testing: tests whether alpha pixel contributes to the colour buffer
• Alpha to coverage: multisampling for transparency billboards (grass, foliage, trees etc)

-----------------------------------------------------------------
RESULT rgb = (SRCBLEND * SRCrgb) [BLENDOP] (DESTBLEND * DESTrgb)
-----------------------------------------------------------------
DESTrgb = pixel colour currently in buffer from previous rendering
SRCrgb = pixel colour being generated by shader

DEFAULT ALPHA BLENDING
AlphaBlendEnable = true
SrcBlend = SrcAlpha
DestBlend = InvSrcAlpha
BlendOp = Add

DEFAULT ALPHA TESTING
AlphaTestEnable = true;
AlphaFunc = GreaterEqual; (only accept if alpha >= 128)
AlphaRef = 128; 

BLENDOP
Add:          (SRCBLEND * SRCrgb) + (DESTBLEND * DESTrgb)
Subtract:     (SRCBLEND * SRCrgb) - (DESTBLEND * DESTrgb)
RevSubtract:  (DESTBLEND * DESTrgb) - (SRCBLEND * SRCrgb)
Min:          min(SRCBLEND * SRCrgb, DESTBLEND * DESTrgb)
Max:          max(SRCBLEND * SRCrgb, DESTBLEND * DESTrgb)

ALPHAFUNC
Never:        Don't accept pixel into buffer
LessEqual:    Only accept pixel into buffer if <= AlphaRef
Less:         Only accept pixel into buffer if < AlphaRef
GreaterEqual: Only accept pixel into buffer if >= AlphaRef
Greater:      Only accept pixel into buffer if > AlphaRef
Always:       Always add to pixel buffer

SRCBLEND / DSTBLEND
Zero           (0, 0, 0, 0)
One            (1, 1, 1, 1)
SrcColor       (Rˢ, Gˢ, Bˢ, Aˢ)
InvSrcColor    (1-Rˢ, 1-Gˢ, 1-Bˢ, 1-Aˢ)
SrcAlpha       (Aˢ, Aˢ, Aˢ, Aˢ)
InvSrcAlpha    (1-Aˢ, 1-Aˢ, 1-Aˢ, 1-Aˢ)
DestAlpha      (Aᵈ, Aᵈ, Aᵈ, Aᵈ)
InvDestAlpha   (1-Aᵈ, 1-Aᵈ, 1-Aᵈ, 1-Aᵈ)
DestColor      (Rᵈ, Gᵈ, Bᵈ, Aᵈ)
InvDestColor   (1-Rᵈ, 1-Gᵈ, 1-Bᵈ, 1-Aᵈ)
SrcAlphaSat    (f, f, f, 1) where f = min(Aˢ,1-Aᵈ)

///////////////////////////////////////////////////////////////////////////////////////////////////
//STENCILING
///////////////////////////////////////////////////////////////////////////////////////////////////

if(ref & mask [operator] value & mask == true) { accept pixel }

NEVER:           Stencil test always fails
ALWAYS:          Stencil test always succeeds
LESS:            <
EQUAL:           ==
LESSEQUAL:       <=
GREATER:         >
NOTEQUAL:        !=
GREATEREQUAL:    >=                     

KEEP: Keep value currently in stencil buffer
ZERO: Specifies to set the stencil buffer entry to zero.
REPLACE: Replace the buffer entry with stencil-reference value
INCRSAT: Increment the stencil buffer entry, clamps to max
DECRSAT: Decrement the stencil buffer entry, clamps to 0
INVERT: Invert the bits of the buffer entry
INCR: Increment the buffer entry, wraps to 0 if goes over max 
DECR: Decrement the buffer entry, wraps to max if goes under 0

///////////////////////////////////////////////////////////////////////////////////////////////////
//TRANSFORMATIONS
///////////////////////////////////////////////////////////////////////////////////////////////////

----------------
|  YAW:    Y   |
|  PITCH:  X   |
|  ROLL:   Z   |
----------------

EULER ANGLES
• Set of pitch, roll, yaw combined to form a matrix
• Suffer from gimbal lock
• Less storage space needed (3 values)

MATRICES: 
• Suffer from gimbal lock if used with Euler Angles
• More storage space needed (12 values)
• Slow, rounding errors

QUATERNIONS: 
• No Gimbal lock
• Less storage space needed (4 values)
• Fast, less rounding errors

GIMBAL LOCK
• A set of three gimbals mounted together to allow three degrees of freedom
• If the middle gimbal is rotated greater than 90, the top and bottle gimbals 
  are aligned and in gimbal lock losing a degree of freedom. 

VIEW MATRIX
• Inverse of the Camera World Matrix
• changes the world scene basis so the camera is at the origin

///////////////////////////////////////////////////////////////////////////////////////////////////
//PROJECTION
///////////////////////////////////////////////////////////////////////////////////////////////////

VIEW FRUSTUM:
Pyramid volume from camera to world, has near and front clipping planes

ORTHOGONAL PROJECTION MATRIX:
objects remain same size regardless of depth

PERSPECTIVE PROJECTION MATRIX:
objects different sizes according to depth, uses horizon as vanishing point 

D3DXMatrixPerspectiveFovLH(&projectionMatrix,
                           D3DX_PI/2,    //field of view (α)
                           Width/height  //aspect ratio (R)
                           10.0f,        //z-value of the near view-plane (n)
                           1000.0f);     //z-value of the far view-plane (f)

PROJECTING VERTS INTO SCREEN SPACE:
For view space coordinates x,y positions need to be between [-1,1]
For view space coordinate z, depth needs to be between [0,-1]

tan(b/2) = R*tan(α/2)
tan(b/2)*n = W/2
tan(α/2)*n = H/2

 A = 1/(R*tan(α/2))
 B = 1/(R*tan(b/2))
 C = f/(f-n)
 D = -fn/(f-n)

         | A 0 0 0 |
[x y z 1]| 0 B 0 0 | = [Ax By (Cz+D)  z]
         | 0 0 C 1 |   HOMOGENEOUS CLIP SPACE
         | 0 0 D 0 |
         PROJ MATRIX

In homogeneous clip space: culling/clipping
If x,y is in range [-w,w] and z is in range [0,w] then okay
To get final coordinate, divide by w (which is screen space z)

[x' y' z' 1] = [Ax/z  By/z  C+(D/z)  1]
 --------------------------------------
| x' = x/(zRtan(α/2))        = Ax/z    |
| y' = y/(ztan(α/2))         = By/z    |
| z' = (f/f-n)-(fn/(z(f-n))) = C+(D/z) |
 --------------------------------------

///////////////////////////////////////////////////////////////////////////////////////////////////
//OPTIMISATION
///////////////////////////////////////////////////////////////////////////////////////////////////

FARPLANE CULLING
• Any objects past the farplane are culled
• Limitation is if plane is too close objects seen disappearing
• This can be fixed by using fog to hide far distances

FRUSTUM CULLING
• Only objects in frustum are drawn. 
• If Polygon outside it's not visible and hence discarded
• If partially inside its clipped so outside parts are removed

FRONT/BACKFACE CULLING
• Winding order of vertices indicates which way polygon is facing

CLIPPING
• Any screen space coordinates outside [–1,–1,0] to [1,1,1] culled

OCCLUSION CULLING
• Identifies parts of the scene visible/not visible to the viewer
• Objects behind other objects are discarded
• Can use a plane to represent occluder *similar to frustum culling)
• Can use Potential Visible Sets for indoor scenes

OPTIMIZATION TIPS
• Don't allocate stencil if you don’t use it
• R5G6B5 color sufficient for dynamic reflection maps
• Use low resolution (<256x256) 8-bit normalization cube-maps
• Use half instead of float where strict precision isn't important
• Render a depth-only pass before color pass to reduce pixel shader use

///////////////////////////////////////////////////////////////////////////////////////////////////
//TEXTURES
///////////////////////////////////////////////////////////////////////////////////////////////////

TGA = Targa
PNG = Portable Network Graphics
JPEG = Joint Photography Experts Group
BMP = Bitmap
GIF = Graphics Interchange Format

8bit   RGB:  Only 256 colors to use
24bit  RGB:  Each channel has 8bits (256 colors)
32bit  ARGB: Each channel has 8bits (256 colors) including 8bit alpha channel

SANS-SERIF FONT: rounded edges of characters
SERIF FONT: little lines on edges of characters
TEXTURE MAPPING: UV coordinates for 2D image
CUBE MAPPING: UVW coordinates for 3D cube image
MINFILTER: Texture filter used when shrinking textures
MAGFILTER: Texture filter used when magnifying textures

POINT FILTERING: 
• Nearest Neighbour/Box Filtering
• Nearest texel is chosen to the given UV coordinates
• If coordinates are on texel border, UVs are rounded

LINEAR FILTERING:
• Bilinear/Trilinear filtering
• Looks at 2x2 texels surrounding the UVs and calculates color using weights
• If UVs totally in one texel: 100% that texel
• If UVs on border between two texels: 50% each
• If UVS on border between four texels: 25% each
• Trilinear: Fixes artifact occurs when stitching various mipmap levels together

ANISOTROPIC FILTERING: 
• Most consuming of all filters
• Avoids blur at sharp angles/distances
• Prevents distortion when angle between camera forward vector and poly normal is large

MIPMAP:
• Mip = multum in parvo; 'many things in a small place'
• Series of power of 2 texture created from original texture

MIPFILTER:
• None disables mipmapping
• Point chooses mipmap level that is closest in size to geometry and filter
• Linear shooses Two mipmap levels that are closest in size to geometry then
  filter both and lineraly combine them

PROJECTIVE TEXTURING:
• Method of projecting a texture into a 3D scene
• Transform local position of vert by light's worldViewProj matrix
• Pass position to pixel shader
• Position will be in homogenous clip space so divide by w
• Scale the position from [-1,1] to [0,1] for proper texture coords
• Sample the texture to be projected 

GAMMA CORRECTION
• the relationship between a pixel's numerical value and its actual luminance

SRGB COLOR SPACE
• Texture blending operations are done in linear space
• sRGB format is gamma corrected color which produce incorrect results in linear space

///////////////////////////////////////////////////////////////////////////////////////////////////
//TEXTURE COMPRESSION
///////////////////////////////////////////////////////////////////////////////////////////////////

LOSSY COMPRESSION: Filesize over quality
LOSSLESS COMPRESSION: Quality over filesize
NORMAL COMPRESSION: Compressions not recommended since compressing normal 
                    maps can un-normalize normals

===========================================================================
RUN LENGTH ENCODING: 
===========================================================================
• lossless encoding
• aaabbccc ==> a3b2c3
• problem is lots of 1 values and encoding doubles the size
• solved by using a marker to indicate where encoding has happened
• close colored pixels can be merged into the one color and counted in run

===========================================================================
HUFFMAN ENCODING:
===========================================================================
• lossless encoding
• uses binary tree/priority queue

1) Find frequency of every character used
2) Create a node for every character used and store in a priority queue
3) Each node is sorted due to it's frequency number (least to greatest)
4) The top two nodes with the smallest frequency are removed and put as children to a new node
5) This new node is given a frequency that equals the combined children's frequency
6) The new node is inserted into the priority queue
7) Continue this until there is one large node left in the queue creates the tree
8) Traverse through the graph (left gives 0, right gives 1) and store the path taken to the correct letter
9) Create a Huffman table (array) to store the path information

///////////////////////////////////////////////////////////////////////////////////////////////////
//DETAIL MAPPING
///////////////////////////////////////////////////////////////////////////////////////////////////

DETAIL MAPPING: Changes interpolated normal depending on map
INTERPOLATED NORMAL: Normal in pixel shader for specific pixel of surface; makes surface smooth
OBJECT SPACE MAPPING: Map is unique to specific object (rainbow)
TANGENT SPACE MAPPING: Map can be reused (purple/blue/red)

BUMP MAP
• Created from height map/grayscale image (no additional geometry)

NORMAL MAP
• Created from difference of high/low res mesh (no additional geometry)

PARALLAX MAP
• Creates illusion of depth by displacing UV coordinates
• Find view angle (angle relative to the surface normal) and value from a height map using UV coordinates
• Use both to calculate new UV coordinates to access tex2D information
• Steeper view-angles = more displacement giving illusion of depth as the view changes

DISPLACEMENT MAP
• Direction vector read from displacement map and added to vertex position moving it to another place

///////////////////////////////////////////////////////////////////////////////////////////////////
//ANTIALIASING
///////////////////////////////////////////////////////////////////////////////////////////////////

 -------------------------------------------------------------
| FINAL PIXEL += WEIGHTING * SAMPLED PIXEL AROUND FINAL PIXEL |
 -------------------------------------------------------------

===========================================================================
SUPERSAMPLING TECHNIQUES
===========================================================================

DOWNSAMPLING/FULL SCENE ANTIALIASING (FSAA): 
• Renders at an increased resolution and resizes down
• By doubling screen size you get 4 samples per pixel

ACCUMULATION BUFFER METHOD
• Screen is rendered 4 times each with view moved by half a pixel in x/y
• Screens summed up in accumulation buffer and averaged (/4)

MULTISAMPLING
• Optimized supersampling where some components are not supersampled
• Downside is edges of alpha objects are still aliased

===========================================================================
ANTIALIASING SAMPLING PATTERNS
===========================================================================

ADAPTIVE SAMPLING: 
• Each pixel is averaged with the pixel's around it

GRID SAMPLING: 
• Use on final texture and blur pixels with sharp changes from neighbours

RANDOM SAMPLING: 
• Randomly samples pixels around center pixel; some areas too little/too much this way

POISSON DISC SAMPLING: 
• Random sampling with additional checks to whether samples are too close to each other

///////////////////////////////////////////////////////////////////////////////////////////////////
//COLOUR BLENDING
///////////////////////////////////////////////////////////////////////////////////////////////////

HSB (Hue/Saturation/Brightness)        Cylindrical colour representation
CMYK (Cyan/Magenta/Yellow/Key[Black])  Subtractive colour model
RGB (Red/Green/Blue)                   Additive colour model

HUE = Particular colour in rainbow
SATURATION = How rich a colour is
VALUE = How much Black/White a colour has
TINTS = Saturation decreases
SHADES = Value decreases
TONES = Saturation/Value decreases

Converting HSV/RGB: http://www.poynton.com/PDFs/coloureq.pdf p15
Colour Blending: http://www.stuartdenman.com/improved-color-blending/

• Linear blending loses saturation between colours
• Blending must occur in polar coordinate space to maintain saturation
• Polar coordinate space: HSV/HSB, CIE-Lab
• Note add primary colour = 6 check to primary colour = 0 when blending hues

--------------------------------------------------------------------------------------------
Polar Coordinate Space Blending:
--------------------------------------------------------------------------------------------
diff = hue2 - hue1
if (hue1 > hue2) then swap(hue1, hue2), diff = -diff, blendValue = 1 - blendValue
if (diff > 180) then hue1 = hue1 + 360, hue = (hue1 + blendValue * (hue2 - hue1)) mod 360
if (diff <= 180) then hue = hue1 + blendValue * difference
where blendValue = [1,0] and hue/hue1/hue2 = [0,360]
--------------------------------------------------------------------------------------------

///////////////////////////////////////////////////////////////////////////////////////////////////
//LIGHTS
///////////////////////////////////////////////////////////////////////////////////////////////////

DIRECTIONAL LIGHTS 
• Direction only
• Used to represent broad light source at a distance, illuminating whole scene
• Light moves in one direction, hitting surfaces, no attenuation used
• Not affected by attenuation and range

POINT/OMNI LIGHTS 
• Position only
• Emits light from all directions
• Affected by attenuation and range

SPOT LIGHTS 
• Direction and Position
• Emits light in one direction that spreads out as distance increases
• Affected by falloff, attenuation, and range and uses theta/phi values
• Vertex position within inner or outer cone is determined to determine the brightness
• THETA VALUE: Radian angle of the spotlight's inner cone (brightest)
• PHI VALUE: Radian angle for the outer cone of light
• FALLOFF: Controls how light intensity decreases between the outer and inner cones; set as 1 for even

BLOOM LIGHTS
• Glow around an object that resembles a halo
• Occurs when eyes/camera suddenly views a very bright object

LENS FLARE
• Scattered light reflected from within the cameras lens

LIGHT SHAFTS
• Light scatters off particles suspended in the media (Dust, water vapour)
• Occurs when light enters/exits materials such as a window
• Draw polygons emitting from light source and use additive blending
• As polygon's vertices become more distant from light they become more transparent

///////////////////////////////////////////////////////////////////////////////////////////////////
//DIRECT LIGHTING
///////////////////////////////////////////////////////////////////////////////////////////////////

EMISSIVE
• How much light is emitted from object

ATTENUATION
• How much light fades into distance
• Multiply by Specular/Diffuse models

LUMINANCE
• Intensity of light per unit area of its source

DIFFUSE
• The amount of light hitting a given point on a surface depends on the position
  of the lights around the surface and the direction the surface is facing.

SPECULAR
• Light reflecting near/exactly in the opposite direction of incoming light

REFLECTION:
• Rasterization uses reflection vector as set of coordinates to get colour from cube map. 
• Ray tracing uses primary ray which is reflected and used to trace the scene to see what the ray hits. 
• Colour chosen is combined with color of original object that was reflected

REFRACTION:
• When light passes through two different materials of different densities the light direction changes. 
• RI = Refractive index of material passing into

///////////////////////////////////////////////////////////////////////////////////////////////////
//INDIRECT LIGHTING
///////////////////////////////////////////////////////////////////////////////////////////////////

GLOBAL ILLUMINATION (INDIRECT LIGHTING): 
• Surfaces illuminated by light reflected off other surfaces
• Often stored in light maps due to being expensive to calculate

==================================================================================================
INDIRECT LIGHTING EFFECTS FROM MATERIALS
==================================================================================================

• If a light bounces off a diffuse surface a color-bleeding happens.
• If a light bounces off a specular surface a caustics reflection happens. 
• If a light travels through a refracted surface a refracted caustics happens.
• If a light is absorbed by a surface and leaves from opposite direction, subsurface scattering happens

COLOR/LIGHT BLEEDING: 
• Light that has reflected off one surface to another bringing
  with it some of its color which is seen on the second surface

CAUSTICS: 
• Reflection of light off a shiny object or focusing of light through a 
  transparent object to produce bright highlights on another object

SUBSURFACE SCATTERING: 
• Light enters, scatters around and leaves at a different point

AMBIENT LIGHTING:
• Light spread equally in all directions without falloff, constant value

==================================================================================================
AMBIENT OCCLUSION
==================================================================================================

• Used to define the occlusion amount of a point in the scene (vertex or pixel depending on precision)
• Each point sends multiple rays into the scene and tests for intersection against
  all geometry or can send out rays to test against itself for self shadowing
• Ratio of hits/misses is added and average float is found for that point
• Average multiplied by ambient light

==================================================================================================
RADIOSITY
==================================================================================================

• Considers everything a light source, and every surface can potentially light another surface
• Scene divided up into patches and view factor/form factor is computed for each patch compared to others
• Form factor describes how well patches can see each other; far away or obstructed means smaller factor
• Form factor used to generate the brightness of each patch taking into account diffuse/reflections/shadows

///////////////////////////////////////////////////////////////////////////////////////////////////
//MATERIALS / SURFACES
///////////////////////////////////////////////////////////////////////////////////////////////////

GOURAUD SHADING [DIFFUSE]: 
• Per-vertex diffuse lighting using linear interpolation of colour between verts

BLINN-PHONG SHADING [SPECULAR]: 
• Uses half-vector for specular calcuation

PHONG SHADING [SPECULAR]: 
• Uses reflection-vector for specular calcuation

BIDIRECTIONAL REFLECTANCE DISTRIBUTION FUNCTION (BRDF):
• Describes how an object reflects/absorbs light from different angles

CONDUCTIVE MATERIALS (metals)                    
• Reflections are tinted

DIELECTRICS (non-metals)
• Reflections are always white except when abosorption/transmission of light 
  occurs, tinting the light (ie. subsurface scattering)
 
FRESNAL SURFACES
• Display one colour when viewed straight on and a different colour at side angles
• Used to: fade out reflections towards edges, brighten edges, make edges more transparent, two tone colour mixing

///////////////////////////////////////////////////////////////////////////////////////////////////
//HDR LIGHTING
///////////////////////////////////////////////////////////////////////////////////////////////////

TONE MAPPING
Maps the high dynamic range (HDR) of luminance values of real world lighting
to the limited range of the screen by dividing scene into set of zones.

  • Zone: range of luminance values
  • Middle gray: middle brightness region of the scene
  • Dynamic range: ratio of the highest scene luminance to the lowest scene luminance
  • Key: subjective measurement of scene lighting varying from light to dark

///////////////////////////////////////////////////////////////////////////////////////////////////
//SHADOWS
///////////////////////////////////////////////////////////////////////////////////////////////////

OCCLUDER: Any object in scene that casts shadows
UMBRA: Region that is completely in shadow and fully occluded
PENUMBRA: Area outside the umbra that gradually softens with distance
  
==================================================================================================
SHADOW MAPPING
==================================================================================================

CREATING SHADOW MAP
• Look at scene from point of view of light source 
• Create shadow map via writing scene depth to rendertarget from the light's perspective

USING SHADOW MAP
• Transform vertex by light view projection matrix to get position in light space
• If depth in shadow map is /w, make sure /w for position in pixel shader
• Compare this to the position saved in the shadow map (also in light space)
• If depth is further away than the depth in shadow map the object is in shadow of another object

ADVANTAGES:
• Cheaper to use
• Easy to blur and make into soft shadows

DISADVANTAGES:  
• Dependent on size/depth of shadow map
• Suffers from artefacts/aliasing problems
• Stitching artifacts:
    - Occurs when depth value of shadow is close to surface
    - Solved by offsetting the shadow depth value retrieved by an amount
    - Solved by turning on front-face cull when creating shadow map

==================================================================================================
SHADOW PROJECTION
==================================================================================================

• Shadow-projection matrix is created to scale anything rendered with it into a flat shape. 
• Light direction is used to control direction from which shadows appear once rendered. 
• The object is projected onto a plane then rendered as a separate primitive.

ADVANTAGES:     
• Easy to implement
• Doesn't require any hardware support such as shadow mapping
• Shadows can be created out of any object or an imposter can be used

DISADVANTAGES:  
• Doesn’t work well on specular surfaces 
• Difficult with non-flat surfaces, stencil buffer fixes this
• Can’t render self shadows
• Difficult to make into soft shadows
• Not a good representation of object
• z-fighting: 
    - close coplanar planes confuses the depth buffer for what to render first
    - Fixed by rendering at an offset or enabling hardware to take care of offset

==================================================================================================
SHADOW VOLUMES
==================================================================================================

• Project the outline of an object into the scene based on the light position. 
• New geometry is created using this silhouette.

PIPELINE:
• Find the edges of an object that define the silhouette and create edge list
• Calculate new geometry from edge list and light vector and store into its own vertex buffer
• Create a counter that will increment/decrement for every surface rendered to the stencil buffer
• Render scene with back-face culling on; increment for every surface rendered
• Render with front-face culling on; decrement for every surface rendered
• If an object is within a shadow volume after two stencil tests the stencil buffer will have 1, if not, 0
• Clear the screen to black
• Render scene normally using results to only render to screen pixels set to 0, leaving sections with 1 black

CARMAK'S REVERSE:
If camera is inside a shadow volume counting for stencil buffers can be incorrect. 
Pixels that should not be in shadow are considered in shadow. Solution:  
  • Render with front-face culling first and increment stencil buffer whenever depth test fails
  • Render with back-face culling second and decrement stencil buffer whenever depth test fails

ADVANTAGES:     
• No aliasing/artefact problems
• Can self shadow
• More accurate representation of model

DISADVANTAGES:  
• Geometry dependent/expensive
• Requires additional data for quick determination of silhouette (object edge list)
• Difficult to make into soft shadows
 
==================================================================================================
SOFT SHADOWS
==================================================================================================

SHADOW MAP: 
• Render only shadows from the shadow map onto a surface and blur using a bloom filter
• Scene rendered again blending the soft shadows into the scene

SHADOW PROJECTION/VOLUME:
• Use two objects: One for the umbra and one for penumbra, fading out penumbra 
• Jittering: Render the shadow more than once, each time in a 
  different position and blend with previous renders

///////////////////////////////////////////////////////////////////////////////////////////////////
//TERRAIN GENERATION
///////////////////////////////////////////////////////////////////////////////////////////////////

MIDPOINT DISPLACEMENT ALGORITHM
• Start with basic four vertex shape and slip by adding vertex in middle
• Get x/z values of middle vertex from midpoint of surrounding vertices
• Get y value of middle vertex from a value between -d/2 and d/2
• Continue to split new four faces multiplying d by 2^-r each time
• Filter to remove sharp transitions
• Smaller R = rougher terrain

FAULT FORMATION ALGORITHM
• Starts with grid for terrain and creates random line accross the terrain
• Raise vertices on one side of the line and lower on other by amount d
• Create another line and repeat, reducing d each pass
• More passes = rougher terrain

///////////////////////////////////////////////////////////////////////////////////////////////////
//ANIMATION
///////////////////////////////////////////////////////////////////////////////////////////////////

PAL:  25fps     576 pixel lines  720 × 576
NTSC: 29.97fps  525 pixel lines  720 × 486
INTERLACE: for tvs to prevent shuttering artifacts, frame is split into two fields
PROGRESSIVE: frame is drawn top to bottom

3 POINT LIGHTING SETUP
• KEY LIGHT: Light source the scheme is built around; main provider of light
• FILL LIGHT: Helps control contrast by filling in dark shadows created by key light
• BACK LIGHT: Defines the edge around the subject and seperates them from background

DEPTH OF FIELD:
• Smaller iris opening in camera = less exposure and light entering = more depth of field
• Larger iris opening in camera = more exposure and light entering = less depth of field
• Wide angle/short focal length lens = greater DOF
• Narrow angle/long focal length lens = smaller DOF
• Subject far away = greater DOF
• Subject up close = smaller DOF

///////////////////////////////////////////////////////////////////////////////////////////////////
//PRIMITIVES
///////////////////////////////////////////////////////////////////////////////////////////////////

POINT LISTS:  .    .    . .   .
LINE LIST: ._________________. 
LINE STRIP: ._______._______.___._______._____.

TRIANGLE LISTS:
     __
    |\ | Triangle1 {1,2,3} Limitation is no sharing of vertices
    |_\| Triangle2 {3,4,1} which increases vertex count

TRIANGLE STRIPS: 
     ___
    |\ |\  Specify first four points then one
    |_\|_\ point for every new triangle in strip

TRIANGLE FANS:
     ____
    |\  /| All triangles connect
    | \/ | to a common point
    | /\ |
    |/__\|

CONVEX POLYGONS: line between two points in polygon never crosses border 
CONCAVE POLYGONS: line between two points in polygon can cross border
POLYHEDRA: three dimensional object with flat faces and straight edges
POLYTOPES: convex hulls of finite points sets (line segments, triangles, polyhedra)
QUADRICS: spheres, cones, cylinders